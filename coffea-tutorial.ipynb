{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af33c56-31f0-4714-9c7a-2fae3b1e4d11",
   "metadata": {},
   "source": [
    "#  Framework: Current Status and Recent Updates\n",
    "\n",
    "### Warning: This tutorial assumes some familiarity with columnar analysis and the uproot+awkward way of dealing with HEP data\n",
    "\n",
    "## Scope of this tutorial\n",
    "This tutorial is meant to present the current status of the `coffea` framework and the recent updates we had this past year.\n",
    "\n",
    "## Columnar analysis and coffea\n",
    "What is `coffea`? Coffea (Columnar Object Framework For Effective Analysis) is a set of basic tools and wrappers for enabling not-too-alien syntax when running columnar Collider HEP analysis.\n",
    "\n",
    "What is columnar analysis:\n",
    "\n",
    "* Event loop analysis:\n",
    "    - Load relevant values for a specific event into local variables\n",
    "    - Evaluate several expressions\n",
    "    - Store derived values\n",
    "    - Repeat (explicit outer loop)\n",
    "* Columnar analysis:\n",
    "    - Load relevant values for many events into contiguous arrays\n",
    "    - Evaluate several array programming expressions\n",
    "        - Implicit inner loops\n",
    "        - Plan analysis by composing data manipulations\n",
    "    - Store derived values\n",
    "\n",
    "In physics we're dealing with [jagged or ragged arrays](https://en.wikipedia.org/wiki/Jagged_array). A ragged array is something like this:\n",
    "\n",
    "```\n",
    "[[1, 2, 3],\n",
    " [4],\n",
    " [],\n",
    " [5, 6]]\n",
    "---------------------\n",
    "type: 4 * var * int64\n",
    "```\n",
    "\n",
    "In the pythonic HEP ecosystem, we deal with those kinds of arrays using [awkward](https://github.com/scikit-hep/awkward). Awkward Arrays are general tree-like data structures, like JSON, but contiguous in memory and operated upon with compiled, vectorized code like NumPy. For more information, please visit the [awkward array docs](https://awkward-array.org/doc/main/index.html) and/or see [previous talks from Jim Pivarski](https://github.com/jpivarski-talks/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630956e1-f264-4471-a22e-61de49322f94",
   "metadata": {},
   "source": [
    "## NanoEvents\n",
    "\n",
    "NanoEvents is a Coffea utility to wrap flat nTuple structures (such as the CMS [NanoAOD](https://www.epj-conferences.org/articles/epjconf/pdf/2019/19/epjconf_chep2018_06021.pdf) format) into a single awkward array with appropriate object methods (such as Lorentz vector methods$^*$), cross references, and nested objects, all accessed from the source ROOT TTree via uproot. The interpretation of the TTree data is configurable via [schema objects](https://coffea-hep.readthedocs.io/en/latest/modules/coffea.nanoevents.html#classes), which are community-supplied  for various source file types. These schema objects allow a richer interpretation of the file contents than the `uproot` methods. Currently available schemas include:\n",
    "\n",
    "   - `BaseSchema`, which provides a simple representation of the input TTree, where each branch is available verbatim as `events.branch_name`.  Any branches that uproot supports at \"full speed\" (i.e. that are fully split and either flat or single-jagged) can be read by this schema;\n",
    "   - `NanoAODSchema`, which is optimized to provide all methods and cross-references in CMS NanoAOD format;\n",
    "   - `PFNanoAODSchema`, which builds a double-jagged particle flow candidate colllection `events.jet.constituents` from compatible PFNanoAOD input files;\n",
    "   - `TreeMakerSchema` which is designed to read TTrees made by [TreeMaker](https://github.com/TreeMaker/TreeMaker), an alternative CMS nTuplization format;\n",
    "   - `PHYSLITESchema`, for the ATLAS DAOD_PHYSLITE derivation, a compact centrally-produced data format similar to CMS NanoAOD; and\n",
    "   - `DelphesSchema`, for reading Delphes fast simulation [nTuples](https://cp3.irmp.ucl.ac.be/projects/delphes/wiki/WorkBook/RootTreeDescription).\n",
    "\n",
    "We welcome contributions for new schemas, and can assist with the design of them.\n",
    "\n",
    "$^*$ Vector methods are currently made possible via the [coffea vector](https://coffea-hep.readthedocs.io/en/latest/modules/coffea.nanoevents.methods.vector.html) methods mixin class structure. In a future version of coffea, they will instead be provided by the dedicated scikit-hep [vector](https://vector.readthedocs.io/en/latest/) library, which provides a more rich feature set. The coffea vector methods predate the release of the vector library.\n",
    "\n",
    "In this demo, we will use NanoEvents to read a small CMS NanoAOD sample. The events object can be instantiated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b40aacb-1538-41c4-8c65-5b2b8eabe1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "\n",
    "NanoAODSchema.warn_missing_crossrefs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790628d-372e-41bd-a97e-5855b35bdcb8",
   "metadata": {},
   "source": [
    "In the factory constructor, we also pass the desired schema version for this file and some extra metadata that we can later access with `events.metadata`. In a later example, we will show how to set up this metadata in coffea processors where the `events` object is pre-created for you. Consider looking at the [from_root](https://coffea-hep.readthedocs.io/en/latest/api/coffea.nanoevents.NanoEventsFactory.html#coffea.nanoevents.NanoEventsFactory.from_root) class method to see all optional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043ff641-c596-40f9-9176-381cc7aa548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/nano_dy.root\"\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {fname: \"Events\"},\n",
    "    schemaclass=BaseSchema,\n",
    "    mode=\"eager\",\n",
    "    metadata={\"dataset\": \"DYJets\"},\n",
    ").events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1a13c-5298-4083-a16b-6c7c13d5c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Electron_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036b42f-9b54-4994-9df1-5d568069129c",
   "metadata": {},
   "source": [
    "But with `BaseSchema`, we are not getting anything more than a plain `uproot.open(...).arrays()` gets us. Since this is a `NanoAOD` file, let's use `NanoAODSchema`. This allows us to structure our array in a way that is very meaningful to do physics with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a489c-3206-4d23-ac20-83e7922b5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/nano_dy.root\"\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {fname: \"Events\"},\n",
    "    schemaclass=NanoAODSchema,\n",
    "    mode=\"eager\",\n",
    "    metadata={\"dataset\": \"DYJets\"},\n",
    ").events()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98731eea-6f6c-4982-940f-540a5849c7de",
   "metadata": {},
   "source": [
    "The `events` object is an awkward array, which at its top level is a record array with one record for each \"collection\", where a collection is a grouping of fields (TBranches) based on the naming conventions of [NanoAODSchema](https://coffea-hep.readthedocs.io/en/latest/api/coffea.nanoevents.NanoAODSchema.html). For example, in the file we opened, the branches:\n",
    "```\n",
    "Generator_binvar\n",
    "Generator_scalePDF\n",
    "Generator_weight\n",
    "Generator_x1\n",
    "Generator_x2\n",
    "Generator_xpdf1\n",
    "Generator_xpdf2\n",
    "Generator_id1\n",
    "Generator_id2\n",
    "```\n",
    "are grouped into one sub-record named `Generator` which can be accessed using either getitem or getattr syntax, i.e. `events[\"Generator\"]` or `events.Generator`. e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39312f44-0469-4984-bbed-6ee8330d6437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.Generator.id1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdfe8a2-1089-475e-94a2-39d77ac4d0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all names can be listed with:\n",
    "events.Generator.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633da934-72f2-4ec0-ab09-bbf4e2834b7c",
   "metadata": {},
   "source": [
    "Based on a collection's name or contents, some collections acquire additional _methods_, which are extra features exposed by the code in the mixin classes of the `coffea.nanoevents.methods` modules. For example, although `events.GenJet` has the fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b3e07-0fba-47d0-94dd-90ddb34964f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.GenJet.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ba343-b926-49b4-a588-c758f4c339ea",
   "metadata": {},
   "source": [
    "we can access additional attributes associated to each generated jet by virtue of the fact that they can be interpreted as [Lorentz vectors](https://coffea-hep.readthedocs.io/en/latest/api/coffea.nanoevents.methods.vector.LorentzVector.html#coffea.nanoevents.methods.vector.LorentzVector):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679dadd-b456-467c-96d4-e342d7c59e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.GenJet.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e912d52-1cd5-45d0-a99e-015be977bdce",
   "metadata": {},
   "source": [
    "We can call more complex methods, like computing the distance $\\Delta R = \\sqrt{\\Delta \\eta^2 + \\Delta \\phi ^2}$ between two LorentzVector objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c01c789-ca08-4c39-87da-76bc60b46add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find distance between leading jet and all electrons in each event\n",
    "dr = events.Jet[:, 0].delta_r(events.Electron)\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39195de-0dea-4927-855f-c1c55f08790f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find minimum distance\n",
    "drmin = ak.min(dr, axis=1)\n",
    "drmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532de5b-2e1e-4119-90cb-5ef7ce6653fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a convenience method for this operation on all jets is available\n",
    "events.Jet.nearest(events.Electron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde5599-8777-4fd8-b66e-a211f74b63b9",
   "metadata": {},
   "source": [
    "The assignment of methods classes to collections is done inside the schema object during the initial creation of the array, governed by the awkward array's `__record__` parameter and the associated behavior. See [ak.behavior](https://awkward-array.readthedocs.io/en/latest/ak.behavior.html) for a more detailed explanation of array behaviors.\n",
    "\n",
    "Additional methods provide convenience functions for interpreting some branches, e.g. CMS NanoAOD packs several jet identification flag bits into a single integer, `jetId`. By implementing the bit-twiddling in the [Jet mixin](https://github.com/CoffeaTeam/coffea/blob/7045c06b9448d2be4315e65d432e6d8bd117d6d7/coffea/nanoevents/methods/nanoaod.py#L279-L282), the analsyis code becomes more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb573687-369c-4493-9942-b656a37c5947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(events.Jet.jetId)\n",
    "print(events.Jet.isTight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613eba3b-8e14-4b1f-96f1-4ea27d8a8812",
   "metadata": {},
   "source": [
    "We can also define convenience functions to unpack and apply some mask to a set of flags, e.g. for generated particles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f262a-a89b-45ad-a4fa-4a42eef39afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Raw status flags: {events.GenPart.statusFlags}\")\n",
    "events.GenPart.hasFlags([\"isPrompt\", \"isLastCopy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227293f3-62cb-4e79-81af-944394529c3f",
   "metadata": {},
   "source": [
    "CMS NanoAOD also contains pre-computed cross-references for some types of collections. For example, there is a TBranch `Electron_genPartIdx` which indexes the `GenPart` collection per event to give the matched generated particle, and `-1` if no match is found. NanoEvents transforms these indices into an awkward _indexed array_ pointing to the collection, so that one can directly access the matched particle using getattr syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ca3a1-bedc-4fc9-a0ca-2f48d73fbf16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.Electron.matched_gen.pdgId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120d98f-b787-48c7-9256-280227bb7d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.Muon[ak.num(events.Muon) > 0].matched_jet.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83735a-8e68-4fe4-8058-f35b05ce7216",
   "metadata": {},
   "source": [
    "For generated particles, the parent index is similarly mapped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d982545-0459-4f8a-8b0b-143e48a50a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.GenPart.parent.pdgId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f41d5a1-1c4a-422f-ac0d-d1b55961d446",
   "metadata": {},
   "source": [
    "In addition, using the parent index, a helper method computes the inverse mapping, namely, `children`. As such, one can find particle siblings with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eda3c2-9a22-4c9c-af79-85ef35b2696f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.GenPart.parent.children.pdgId\n",
    "# notice this is a doubly-jagged array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474c1d8-470f-4a97-9913-77c55ca75a93",
   "metadata": {},
   "source": [
    "Since often one wants to shortcut repeated particles in a decay sequence, a helper method `distinctParent` is also available. Here we use it to find the parent particle ID for all prompt electrons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cbf82-c38b-422b-8f23-103f2e269204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "events.GenPart[\n",
    "    (abs(events.GenPart.pdgId) == 11)\n",
    "    & events.GenPart.hasFlags([\"isPrompt\", \"isLastCopy\"])\n",
    "].distinctParent.pdgId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b951b87-d0fb-450c-a026-7c3fff24d231",
   "metadata": {},
   "source": [
    "Events can be filtered like any other awkward array using boolean fancy-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b45f9-2114-4a5e-9e2a-ba537c316d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmevents = events[ak.num(events.Muon) == 2]\n",
    "zmm = mmevents.Muon[:, 0] + mmevents.Muon[:, 1]\n",
    "zmm.mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7910ac-fdf4-4404-a8ef-999c40ded3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a convenience method is available to sum vectors along an axis:\n",
    "mmevents.Muon.sum(axis=1).mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a9362-a9ed-4736-b638-b717099fb08c",
   "metadata": {
    "tags": []
   },
   "source": [
    "As expected for this sample, most of the dimuon events have a pair invariant mass close to that of a Z boson. But what about the last event? Let's take a look at the generator information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e62ee-8ad7-4105-baca-27565c851407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mmevents[-1].Muon.matched_gen.pdgId)\n",
    "print(mmevents[-1].Muon.matched_gen.hasFlags([\"isPrompt\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793e714-54a3-458d-82a9-5cb998e1a4f9",
   "metadata": {},
   "source": [
    "So they are real generated muons, but they are not prompt (i.e. from the initial decay of a heavy resonance)\n",
    "\n",
    "Let's look at their parent particles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9a272-a95a-48e8-bbc4-5e6a935086ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmevents[-1].Muon.matched_gen.parent.pdgId"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bc8e4-08d0-48c5-8a55-51a1547282ff",
   "metadata": {},
   "source": [
    "aha! They are muons coming from tau lepton decays, and hence a fair amount of the Z mass is carried away by the neutrinos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2c46b-6dc7-4a00-a286-1123a83deebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mmevents.Muon.matched_gen.sum().mass[-1])\n",
    "print(mmevents.Muon.matched_gen.parent.sum().mass[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cbdb8-48b3-4490-ba8f-70f54ae056ca",
   "metadata": {},
   "source": [
    "One can assign new variables to the arrays, with some caveats:\n",
    "\n",
    " * Assignment must use setitem (`events[\"path\", \"to\", \"name\"] = value`)\n",
    " * Assignment to a sliced `events` won't be accessible from the original variable\n",
    " * New variables are not visible from cross-references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87efd559-2a87-4f82-90ed-9871018f3ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmevents[\"Electron\", \"myvariable\"] = mmevents.Electron.pt + zmm.mass\n",
    "mmevents.Electron.myvariable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39479e-25a3-4bda-aba3-b8be092159c2",
   "metadata": {},
   "source": [
    "### NanoEvents virtual mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf7a4c-e41e-4db2-86f4-1f55db7dc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/nano_dy.root\"\n",
    "access_log = []\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {fname: \"Events\"},\n",
    "    schemaclass=NanoAODSchema,\n",
    "    mode=\"virtual\",  # is the default\n",
    "    metadata={\"dataset\": \"DYJets\"},\n",
    "    access_log=access_log,\n",
    ").events()\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eb0d75-8538-4b15-b743-967758d31407",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.Electron.pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf927a1e-735a-4897-8251-8ac134e95f26",
   "metadata": {},
   "source": [
    "Everything is lazy until required by an operation. For example, multiplying an array by 1 will load it and the loaded array gets cached onto the itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34b7fa-081a-457f-b2fe-2bcdb5d3141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.Electron.pt * 1)\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e20f6-1b24-4f85-be80-c0093a7e1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.Electron.pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ae1ce-43a2-4a2e-b728-ba176b892964",
   "metadata": {},
   "source": [
    "Things that only need the shape will load only that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96da25-3ef2-4ee1-afb4-9445c5355ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ak.zeros_like(events.Muon.pt))\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e307a2-9e6a-47b2-b5a6-b6074c80793e",
   "metadata": {},
   "source": [
    "There is also a high-level `ak.materialize` function that traverses the input array and materializes any virtual buffers (and returns a new array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bded23-510c-4d8d-9cdc-070e76bbb588",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ak.materialize(events.Muon.eta))\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742ee4e-aee6-409d-a41b-ab36515743d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ak.materialize(events.GenJet))\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f1006-839c-4f38-9eca-8dc074302abc",
   "metadata": {},
   "source": [
    "You don't need to think about virtual arrays more than what we just mentioned. Lazy loading comes for free without mental overhead to the physicist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa69b95-5b94-4ac7-b448-6a62511ac8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.Jet[:, 0].delta_r(events.Electron))\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc4086-a3a8-4921-a9d4-1246783d7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.Jet.jetId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaaffa-2796-4fa3-bd36-b38bd5260d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.Jet.isTight)\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd381fe6-74ef-4816-9d33-5ebc4a9df17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events.Jet.jetId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19f603-b377-446a-834b-2d57e89a08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmevents = events[ak.num(events.Muon) == 2]\n",
    "zmm = mmevents.Muon[:, 0] + mmevents.Muon[:, 1]\n",
    "print(zmm.mass)\n",
    "print(access_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c351a1b-1331-46c7-adfe-4373208e4078",
   "metadata": {},
   "source": [
    "## Analysis tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9314b3d-bc98-4905-936b-02fbb81e42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/nano_dy.root\"\n",
    "access_log = []\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {fname: \"Events\"},\n",
    "    schemaclass=NanoAODSchema,\n",
    "    metadata={\"dataset\": \"DYJets\"},\n",
    "    mode=\"virtual\",\n",
    "    access_log=access_log,\n",
    ").events()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffffe4c-20d1-4646-b4a7-e8baa496013e",
   "metadata": {},
   "source": [
    "### Weights\n",
    "\n",
    "This is a container for event weights and associated systematic shifts, which helps track the product of the weights (i.e. the total event weight to be used for filling histograms) as well as systematic variations to that product. Here we demo its use by constructing an event weight consisting of the generator weight, the $\\alpha_s$ uncertainty variation, and the electron ID scale factor with its associated systematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a7eb8-66c3-406a-b04c-2b2436e48f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from coffea.analysis_tools import Weights\n",
    "\n",
    "weights = Weights(len(events))\n",
    "\n",
    "weights.add(\"genWeight\", events.genWeight)\n",
    "\n",
    "weights.add(\n",
    "    \"alphaS\",\n",
    "    # in NanoAOD, the generator weights are already stored with respect to nominal\n",
    "    weight=ak.ones_like(events.run, dtype=float),\n",
    "    # 31 => alphas(MZ)=0.1165 central value; 32 => alphas(MZ)=0.1195\n",
    "    # per https://lhapdfsets.web.cern.ch/current/PDF4LHC15_nnlo_30_pdfas/PDF4LHC15_nnlo_30_pdfas.info\n",
    "    # which was found by looking up the LHA ID in events.LHEPdfWeight.__doc__\n",
    "    weightUp=events.LHEPdfWeight[:, 32],\n",
    "    weightDown=events.LHEPdfWeight[:, 31],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd080d7-d0ff-41c8-801e-db084158dd5e",
   "metadata": {},
   "source": [
    "A [WeightStatistics](https://coffea-hep.readthedocs.io/en/latest/api/coffea.analysis_tools.WeightStatistics.html) object tracks the smallest and largest weights seen per type, as well as some other summary statistics. It is kept internally and can be accessed via `weights.weightStatistics`. This object is addable, so it can be used in an accumulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69578ca-f0c4-419e-93aa-33027db1f605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights.weightStatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479b9a9-6088-4ce7-938c-cdd3c6aa2891",
   "metadata": {},
   "source": [
    "Then the total event weight is available via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8379b08e-bcc9-426e-b3d9-00829c9b78df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights.weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad8edc-b431-48a7-bc80-16e30436995d",
   "metadata": {},
   "source": [
    "And the total event weight with a given variation is available via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22059d4d-d2e0-4822-bacc-068281417a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights.weight(\"alphaSUp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af533c-a8ce-4a3e-970b-8b87f93dd1d4",
   "metadata": {},
   "source": [
    "all variations tracked by the `weights` object are available via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf62d64-c5b4-4dca-8ecc-befcf0c34859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights.variations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0eac64-40c8-41f5-900f-498311f3d152",
   "metadata": {},
   "source": [
    "### PackedSelection\n",
    "\n",
    "This class can store several boolean arrays in a memory-efficient mannner and evaluate arbitrary combinations of boolean requirements in an CPU-efficient way. Supported inputs include 1D numpy or awkward arrays. This makes it a good tool to form analysis signal and control regions, and to implement cutflow or \"N-1\" plots.\n",
    "\n",
    "Below we create a packed selection with some typical selections for a Z+jets study, to be used later to form same-sign and opposite-sign $ee$ and $\\mu\\mu$ event categories/regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee4de6-bd45-4d94-8816-b6dbbbde33ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from coffea.analysis_tools import PackedSelection\n",
    "\n",
    "selection = PackedSelection()\n",
    "\n",
    "selection.add(\"twoElectron\", ak.num(events.Electron, axis=1) == 2)\n",
    "selection.add(\"eleOppSign\", ak.sum(events.Electron.charge, axis=1) == 0)\n",
    "selection.add(\"noElectron\", ak.num(events.Electron, axis=1) == 0)\n",
    "\n",
    "selection.add(\"twoMuon\", ak.num(events.Muon, axis=1) == 2)\n",
    "selection.add(\"muOppSign\", ak.sum(events.Muon.charge, axis=1) == 0)\n",
    "selection.add(\"noMuon\", ak.num(events.Muon, axis=1) == 0)\n",
    "\n",
    "\n",
    "selection.add(\n",
    "    \"leadPt20\",\n",
    "    # assuming one of `twoElectron` or `twoMuon` is imposed, this implies at least one is above threshold\n",
    "    ak.any(events.Electron.pt >= 20.0, axis=1) | ak.any(events.Muon.pt >= 20.0, axis=1),\n",
    ")\n",
    "\n",
    "print(selection.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313cc3d-09a5-4a2e-88f5-639d374c3c3e",
   "metadata": {},
   "source": [
    "To evaluate a boolean mask (e.g. to filter events) we can use the `selection.all(*names)` function, which will compute the AND of all listed boolean selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79ac5b-d604-47da-af59-952c81827702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selection.all(\"twoElectron\", \"noMuon\", \"leadPt20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53501ca4-93ae-403d-929b-257a7e13ede0",
   "metadata": {},
   "source": [
    "We can also be more specific and require that a specific set of selections have a given value (with the unspecified ones allowed to be either true or false) using `selection.require`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086b8ac-fe17-459b-93f2-e53f8b775b4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selection.require(twoElectron=True, noMuon=True, eleOppSign=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ff9f8-d3ab-468d-80af-92bad93f9a5d",
   "metadata": {},
   "source": [
    "Using the python syntax for passing an arguments variable, we can easily implement a \"N-1\" style selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073b4e3-5bf3-4dab-943f-a9ad17cec66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCuts = [\"twoElectron\", \"noMuon\", \"leadPt20\"]\n",
    "results = {}\n",
    "for cut in allCuts:\n",
    "    nev = ak.sum(selection.all(*(set(allCuts) - {cut})), axis=0)\n",
    "    results[cut] = nev\n",
    "\n",
    "results[\"None\"] = ak.sum(selection.all(*allCuts), axis=0)\n",
    "\n",
    "for cut, nev in results.items():\n",
    "    print(f\"Events passing all cuts, ignoring {cut}: {nev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59bfb6e-718a-4aee-8496-4f509dcf2875",
   "metadata": {},
   "source": [
    "Luckily coffea implements a helper for that and also for a \"Cutflow\" selection (with `.cutflow`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe375db0-897f-4ff5-b7e1-c2b52e4ebd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nminusone = selection.nminusone(\"twoElectron\", \"noMuon\", \"leadPt20\")\n",
    "nminusone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f882d-f9ab-494e-aec1-5c8fa09c433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nminusone.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacd298-49d8-4843-8fe7-d99ba327befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "h, labels = nminusone.yieldhist()\n",
    "h.plot()\n",
    "plt.xticks(plt.gca().get_xticks(), labels, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c42a0-049c-42fb-9568-60df9bf0fd93",
   "metadata": {},
   "source": [
    "## Coffea Processors\n",
    "Coffea relies mainly on [uproot](https://github.com/scikit-hep/uproot) to provide access to ROOT files for analysis.\n",
    "As a usual analysis will involve processing tens to thousands of files, totalling gigabytes to terabytes of data, there is a certain amount of work to be done to build a parallelized framework to process the data in a reasonable amount of time. \n",
    "\n",
    "Since the beginning a `coffea.processor` module was provided to encapsulate the core functionality of the analysis, which could be run locally or distributed via a number of Executors. This allowed users to worry just about the actual analysis code and not about how to implement efficient parallelization, assuming that the parallization is a trivial map-reduce operation (e.g. filling histograms and adding them together).\n",
    "\n",
    "Let's start by writing a simple processor class that reads some CMS open data and plots a dimuon mass spectrum.\n",
    "We'll start by copying the [ProcessorABC](https://coffea-hep.readthedocs.io/en/latest/api/coffea.processor.ProcessorABC.html#coffea.processor.ProcessorABC) skeleton and filling in some details:\n",
    "\n",
    " * Remove `flag`, as we won't use it\n",
    " * Adding a new histogram for $m_{\\mu \\mu}$\n",
    " * Building a [Candidate](https://coffea-hep.readthedocs.io/en/latest/api/coffea.nanoevents.methods.candidate.PtEtaPhiMCandidate.html#coffea.nanoevents.methods.candidate.PtEtaPhiMCandidate) record for muons, since we will read it with `BaseSchema` interpretation (the files used here could be read with `NanoAODSchema` but we want to show how to build vector objects from other TTree formats) \n",
    " * Calculating the dimuon invariant mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956dd9a-4f7e-42e5-b0eb-f85938587e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from hist import Hist\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "\n",
    "\n",
    "class MyProcessor(processor.ProcessorABC):\n",
    "    def process(self, events):\n",
    "        dataset = events.metadata[\"dataset\"]\n",
    "        muons = ak.zip(\n",
    "            {\n",
    "                \"pt\": events.Muon_pt,\n",
    "                \"eta\": events.Muon_eta,\n",
    "                \"phi\": events.Muon_phi,\n",
    "                \"mass\": events.Muon_mass,\n",
    "                \"charge\": events.Muon_charge,\n",
    "            },\n",
    "            with_name=\"PtEtaPhiMCandidate\",\n",
    "            behavior=candidate.behavior,\n",
    "        )\n",
    "\n",
    "        h_mass = (\n",
    "            Hist.new.StrCat([\"opposite\", \"same\"], name=\"sign\")\n",
    "            .Log(1000, 0.2, 200.0, name=\"mass\", label=r\"$m_{\\mu\\mu}$ [GeV]\")\n",
    "            .Int64()\n",
    "        )\n",
    "\n",
    "        cut = (ak.num(muons) == 2) & (ak.sum(muons.charge, axis=1) == 0)\n",
    "        # add first and second muon in every event together\n",
    "        dimuon = muons[cut][:, 0] + muons[cut][:, 1]\n",
    "        h_mass.fill(sign=\"opposite\", mass=dimuon.mass)\n",
    "\n",
    "        cut = (ak.num(muons) == 2) & (ak.sum(muons.charge, axis=1) != 0)\n",
    "        dimuon = muons[cut][:, 0] + muons[cut][:, 1]\n",
    "        h_mass.fill(sign=\"same\", mass=dimuon.mass)\n",
    "\n",
    "        return {\n",
    "            dataset: {\n",
    "                \"entries\": len(events),\n",
    "                \"mass\": h_mass,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48638d84-7d20-415e-8312-62982d547cf3",
   "metadata": {},
   "source": [
    "If we were to just use bare uproot to execute this processor, we could do that with the following example, which:\n",
    "\n",
    " * Opens a CMS open data file\n",
    " * Creates a NanoEvents object using `BaseSchema` (roughly equivalent to the output of reading with plain `uproot`)\n",
    " * Creates a `MyProcessor` instance\n",
    " * Runs the `process()` function, which returns our accumulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1d19e-ef7a-4341-b1af-003ca14e2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/ZZTo4mu.root\"\n",
    "access_log = []\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {filename: \"Events\"},\n",
    "    metadata={\"dataset\": \"ZZTo4mu\"},\n",
    "    schemaclass=BaseSchema,\n",
    "    mode=\"virtual\",\n",
    "    access_log=access_log,\n",
    ").events()\n",
    "p = MyProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5df1d6-8f66-4a90-a88c-9df3e2009cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = p.process(events)\n",
    "out, sorted(set(access_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857baa06-2913-4445-9eab-5881c0c47f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"ZZTo4mu\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905466b1-b10c-4110-8758-32cfc279523b",
   "metadata": {},
   "source": [
    "## Processing and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98702f15-d87f-4c7d-bbcb-f101f0ec54cd",
   "metadata": {},
   "source": [
    "To process multiple files and data at scale in general we need to construct a \"fileset\" first. The fileset specifies our datasets, their files and potentially metadata too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02fe31-a720-4a6f-833a-2e2978de5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = {\n",
    "    \"SMHiggsToZZTo4L\": {\n",
    "        \"files\": {\n",
    "            \"data/SMHiggsToZZTo4L.root\": \"Events\",\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"is_mc\": True,\n",
    "        },\n",
    "    },\n",
    "    \"ZZTo4mu\": {\n",
    "        \"files\": {\n",
    "            \"data/ZZTo4mu.root\": \"Events\",\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"is_mc\": True,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a5e78-2dfa-430e-b93b-4aeb8d1cdc4d",
   "metadata": {},
   "source": [
    "And then we can define an executor and run the processor over all our datasets and their files in chunks and aggregate the results. Let's start by doing that iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b3fcc-4c38-45f1-af07-53aa41c37713",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_run = processor.Runner(\n",
    "    executor=processor.IterativeExecutor(compression=None),\n",
    "    schema=BaseSchema,\n",
    "    chunksize=100_000,\n",
    "    savemetrics=True,\n",
    ")\n",
    "\n",
    "out, metrics = iterative_run(\n",
    "    fileset,\n",
    "    processor_instance=MyProcessor(),\n",
    ")\n",
    "out, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d756bde1-1486-4b75-b2ed-5270c14f6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"ZZTo4mu\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fad2e1-5b16-4e67-a785-a8ed69257f79",
   "metadata": {},
   "source": [
    "Now, if we want to use more than a single core on our machine, we simply change `IterativeExecutor` for `FuturesExecutor`, which uses the python `concurrent.futures` standard library. We can then set the most interesting argument to the `FuturesExecutor`: the number of cores to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050d0f5-fb2d-4935-8c40-2a109437b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_run = processor.Runner(\n",
    "    executor=processor.FuturesExecutor(workers=4, compression=None),\n",
    "    schema=BaseSchema,\n",
    "    chunksize=100_000,\n",
    "    savemetrics=True,\n",
    ")\n",
    "\n",
    "out, metrics = futures_run(\n",
    "    fileset,\n",
    "    processor_instance=MyProcessor(),\n",
    ")\n",
    "out, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326d3be-70af-4748-8733-c9bac5a4ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"ZZTo4mu\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f342f-40b5-4f14-ba39-984bff357d50",
   "metadata": {},
   "source": [
    "Or you can scale accross whole clusters using the `DaskExecutor` which connects to a `dask` client or others like `ParslExecutor` and `TaskVineExecutor`. More executors can be implemented somewhat easily if your computing infrastructure requires them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410cf3ec-a36d-4bfd-8c9d-b63e998a0ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5211ca3-45bf-408f-bc31-4a512c204f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_run = processor.Runner(\n",
    "    executor=processor.DaskExecutor(client=client, compression=None),\n",
    "    schema=BaseSchema,\n",
    "    chunksize=100_000,\n",
    "    skipbadfiles=True,\n",
    "    savemetrics=True,\n",
    ")\n",
    "\n",
    "out, metrics = dask_run(\n",
    "    fileset,\n",
    "    processor_instance=MyProcessor(),\n",
    ")\n",
    "out, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fef2a9-ae8b-4fc6-9163-eae612c1e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"ZZTo4mu\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ad2da8-1642-44ea-9ba6-959a64d97978",
   "metadata": {},
   "source": [
    "Your analysis code is completely independent of the compute infrastructure! You just need to express how to process an arbitrary chunk of events and scaling is then seamless!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273eebf5-e6f2-4747-9ee9-96948d86be08",
   "metadata": {},
   "source": [
    "### Checkpointing\n",
    "\n",
    "Often, the workflow can crash due to reasons beyond our control. An error due to reading over `xrootd`, workers dying can crash our whole workflow. `skipbadfiles` mitigates for that because it runs every single chunk in a try-except block and will catch the error and not raise it. But in that case, if errors happen, you fail to run over some chunks of events. How do you continue from that point? Coffea provides a checkpointing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5fd62-5198-4abd-9cd0-aeb5202ae483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import awkward as ak\n",
    "from datetime import datetime\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import NanoAODSchema\n",
    "\n",
    "\n",
    "class UnstableNanoEventsProcessor(processor.ProcessorABC):\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return {\"cutflow\": {}}\n",
    "\n",
    "    def process(self, events):\n",
    "        if random.random() < 0.75:\n",
    "            raise OSError(\"Random failure for testing checkpointing\")\n",
    "\n",
    "        output = self.accumulator\n",
    "        dataset = events.metadata[\"dataset\"]\n",
    "        output[\"cutflow\"][\"%s_pt\" % dataset] = ak.sum(ak.num(events.Muon, axis=1))\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "\n",
    "\n",
    "today = datetime.now().strftime(\"%Y%m%d\")\n",
    "checkpointer = processor.SimpleCheckpointer(\n",
    "    checkpoint_dir=f\"checkpoints/{today}\", verbose=True\n",
    ")\n",
    "\n",
    "iterative_run = processor.Runner(\n",
    "    executor=processor.IterativeExecutor(compression=None),\n",
    "    schema=NanoAODSchema,\n",
    "    chunksize=100_000,\n",
    "    savemetrics=True,\n",
    "    skipbadfiles=True,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "\n",
    "out, metrics = iterative_run(\n",
    "    fileset,\n",
    "    processor_instance=UnstableNanoEventsProcessor(),\n",
    ")\n",
    "out, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca14160-0fbb-4d51-94f9-e9078181b7b8",
   "metadata": {},
   "source": [
    "## Tracing and preloading\n",
    "\n",
    "Finally, I would like to talk about a couple more features of `NanoEvents` that will soon be part of processing/executing too.\n",
    "The virtual array implementation means that each root branch will be loaded from the root file sequentially when it is first needed wth separate network requests. It is generally more efficient to make a single netgwork request for all the branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f4861-5b82-4653-b09b-ce6254b66e9a",
   "metadata": {},
   "source": [
    "### Preloading\n",
    "\n",
    "We provide a pre-loading capability where the user can specify some branches to pre-load they they know they are going to need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d08c13-b77d-4703-8b50-d4bdad3438e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/ZZTo4mu.root\"\n",
    "access_log = []\n",
    "preload = lambda b: b.name == \"nMuon\" or b.name == \"Muon_pt\"\n",
    "\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {filename: \"Events\"},\n",
    "    mode=\"virtual\",\n",
    "    access_log=access_log,\n",
    "    preload=preload,\n",
    ").events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9e5bb-1916-4eb0-b513-cefedf3934c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 ak.materialize(events.Muon.eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6a7b7-e641-4c66-8d06-739675f81d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 ak.materialize(events.Muon.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61796cfe-2d5d-402d-9ae3-1c5efe57f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c44d1c-149a-4f01-8e4d-8d505f03d087",
   "metadata": {},
   "source": [
    "### Tracing\n",
    "\n",
    "But how do I know which branches I am gonna need? Some times it's obvious. Other times, it's not. But, you can \"trace\" thorugh a processor without loading any data to find out \"as much as you can\" in a try-except fashion because tracing has limitations (you can't make data-dependent decisions for example because there is no data to decide on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65d1ee-64fd-40ef-b3c9-0caac07a5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/ZZTo4mu.root\"\n",
    "access_log = []\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {filename: \"Events\"},\n",
    "    metadata={\"dataset\": \"ZZTo4mu\"},\n",
    "    schemaclass=BaseSchema,\n",
    "    mode=\"virtual\",\n",
    "    access_log=access_log,\n",
    ").events()\n",
    "access_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7d865-df88-48d1-b94b-e8de8497f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents.trace import trace\n",
    "\n",
    "necessary_columns = trace(MyProcessor().process, events)\n",
    "necessary_columns, access_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba06a1-fb34-4bc5-9f21-3d4f9623fb4f",
   "metadata": {},
   "source": [
    "### Tracing and preloading\n",
    "\n",
    "Naturally, these two features play very well together. You can ask to pre-load what the tracing stage found as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f09acc-7558-4a32-ab8a-484a397a6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preload = lambda b: b.name in necessary_columns\n",
    "\n",
    "filename = \"data/ZZTo4mu.root\"\n",
    "access_log = []\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {filename: \"Events\"},\n",
    "    metadata={\"dataset\": \"ZZTo4mu\"},\n",
    "    mode=\"virtual\",\n",
    "    schemaclass=BaseSchema,\n",
    "    access_log=access_log,\n",
    "    preload=preload,\n",
    ").events()\n",
    "\n",
    "out = MyProcessor().process(events)\n",
    "out, sorted(set(access_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73289d7e-c445-499c-9bd0-95d60b6526a0",
   "metadata": {},
   "source": [
    "The goal is to have these optional features as part of the processing/executing stage as some form of pre-processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
